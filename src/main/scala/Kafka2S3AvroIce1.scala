import org.apache.spark.sql.SparkSession
import org.apache.spark.sql.functions.{col, date_format, from_json, from_unixtime}
import org.apache.spark.sql.streaming.Trigger
import org.apache.spark.sql.types.{IntegerType, StringType, StructType}
import org.apache.spark.sql.functions._

object Kafka2S3AvroIce1 {
  def main(args: Array[String]): Unit = {


    val spark: SparkSession = SparkSession.builder()
   // .master("local[1]")
      .appName("Streaming All RTM Kafka fields to S3 in Avro format")
      .getOrCreate()
      spark.conf.set("spark.streaming.kafka.consumer.enable.auto.commit", "false")
      spark.conf.set("spark.streaming.kafka.consumer.enable.idempotence", "true")
      spark.conf.set("spark.streaming.receiver.writeAheadLog.enable", "true")
      spark.conf.set("spark.streaming.kafka.maxRatePerPartition","120000")

    import spark.implicits._
    spark.sparkContext.setLogLevel("ERROR")
    spark.sparkContext.addSparkListener(new MySparkListener())
   // val listener = new MyStreamingQueryListener
   // spark.streams.addListener(listener)
    val bootstrapServers = "10.200.245.83:9092,10.200.58.127:9092,10.200.101.134:9092"
    val topic = "rtm_in_app_bidding_mediation_marketplace"
   val schema = new StructType()
     .add("abActive", StringType)
     .add("abt", StringType)
     .add("adUnit", IntegerType)
     .add("eventTimestamp", StringType)
  /*  .add("applicationId", IntegerType)
     .add("auctionEndTimestamp", IntegerType)
     .add("auctionId", StringType)
     .add("auctionStartTimestamp", IntegerType)
     .add("auctionType", StringType)
     .add("bidPriceRange_lowerBound", DoubleType)
     .add("bidPriceRange_upperBound", DoubleType)
     .add("bidRequestTimestamp", StringType)
     .add("bidResponseTimestamp", StringType)
     .add("bidType", StringType)
     .add("blockedRequest", StringType)
     .add("clearance", DoubleType)
     .add("clientParams_advId", StringType)
     .add("clientParams_advIdType", StringType)
     .add("clientParams_appVersion", StringType)
     .add("clientParams_applicationUserId", StringType)
     .add("clientParams_auid", StringType)
     .add("clientParams_browserUserAgent", StringType)
     .add("clientParams_bundleId", StringType)
     .add("clientParams_clientTimestamp", IntegerType)
     .add("clientParams_connectionType", StringType)
     .add("clientParams_country", StringType)
     .add("clientParams_deviceHeight", IntegerType)
     .add("clientParams_deviceLang", StringType)
     .add("clientParams_deviceMake", StringType)
     .add("clientParams_deviceModel", StringType)
     .add("clientParams_deviceOS", StringType)
     .add("clientParams_deviceOSVersion", StringType)
     .add("clientParams_deviceType", StringType)
     .add("clientParams_deviceWidth", IntegerType)
     .add("clientParams_fs", IntegerType)
     .add("clientParams_isLimitAdTrackingEnabled", StringType)
     .add("clientParams_mobileCarrier", StringType)
     .add("clientParams_secure", IntegerType)
     .add("companyKey", StringType)
     .add("dynamicDemandSourceType", IntegerType)
     .add("eventId", IntegerType)
     .add("eventTimestamp", StringType)
     .add("instanceId", IntegerType)
     .add("instanceLevelConfiguration", StringType)
     .add("instanceType", IntegerType)
     .add("ip", StringType)
     .add("isAuctionWinner", StringType)
     .add("isCoppa", StringType)
     .add("isMarketplace", StringType)
     .add("isMarketplaceDatasource", StringType)
     .add("isTest", StringType)
     .add("numberOfBidRequests", IntegerType)
     .add("numberOfBidResponses", IntegerType)
     .add("price", DoubleType)
     .add("provider", StringType)
     .add("providerId", IntegerType)
     .add("publisherId", IntegerType)
     .add("rank", IntegerType)
     .add("sdkVersion", StringType)
     .add("sessionDepth", IntegerType)
     .add("sessionId", StringType)
     .add("state", StringType)
     .add("time", StringType)
     .add("userAgent", StringType)
     .add("clientParams_consent", StringType)
     .add("isGdpr", StringType)
     .add("activityType", StringType)
     .add("advertiserDomain", StringType)
     .add("brandsDspName", StringType)
     .add("brandsGrossBid", DoubleType)
     .add("brandsLatency", IntegerType)
     .add("brandsSellerVersion", StringType)
     .add("brandsTemplateType", StringType)
     .add("buyerType", StringType)
     .add("categories", StringType)
     .add("connection", StringType)
     .add("demandBundle", StringType)
     .add("demandCategory", StringType)
     .add("demandType", StringType)
*/
    val df = spark.readStream
      .format("kafka")
      .option("kafka.bootstrap.servers", bootstrapServers)
      .option("subscribe",topic)
      .option("startingOffsets","latest")
      .option("failOnDataLoss","false")
      .load()
      val df1 = df.select(from_json($"value".cast("string"), schema).alias("data")
      ).select("data.*")

    val convertedData = df1.withColumn("event_date", date_format(from_unixtime(col("eventTimestamp") / 1000), "yyyy-MM-dd"))
      .withColumn("event_hour", hour(from_unixtime(col("eventTimestamp") / 1000)))

      convertedData.writeStream
          .format("avro")  //spark
          .outputMode("append")
          .option("header", value = true)
          .partitionBy("event_date", "event_hour")
       .trigger(Trigger.ProcessingTime("60 seconds"))
      .option("checkpointLocation", "/Users/mohsinbanedar/Desktop/streaming-iceberg/1")
     .option("path", s"/Users/mohsinbanedar/Desktop/streaming-iceberg/2")
         // .option("path","s3://mobile-streaming-poc/2nd_Jan_2023/RTM-AVRO-FILES-2Jan2023")
       //   .option("checkpointLocation","s3://mobile-streaming-poc/2nd_Jan_2023/RTM-AVRO-FILES-CHECKPOINT-2Jan2023")
          .start()
          .awaitTermination()
  }
}

